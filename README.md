# [Welcome to Recursive Labs](https://recursivelabsai.github.io)
### *And Innovation Begins*


[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.15485942.svg)](https://doi.org/10.5281/zenodo.15485942)


**Forward-Deployed Systems Engineering | Zero-Trust Systems Infrastructure | AI Creative Emergence & Reflective Reasoning Research**
> *AI Research and Utility For Innovators Advancing Discovery At The Frontier*


## Enabling Transparent, Adaptive, and Reliable AI for the Agent Era

Recursive Labs is building foundational infrastructure for the next generation of AI—where agents are composable, memory-aware, and robustly interpretable by design. As language models and agent frameworks become core infrastructure, reliability, traceability, and alignment are no longer add-ons—they are critical requirements for responsible, scalable deployment.

We believe the future of AI will be defined by systems that can reason transparently, adapt persistently, and learn safely in dynamic environments. Our work addresses the biggest challenges facing the field today:

- **Interpretability:** We deliver agent-native tools for attribution, uncertainty quantification, and reasoning traceability—surfacing not just what models predict, but why, how, and where they hesitate.
- **Persistent Memory:** Our universal memory schema enables agents to retain, retrieve, and attribute context across sessions, unlocking robust “save and resume” for complex workflows and collaborative multi-agent systems.
- **Provenance and Trust:** Every decision and state change is anchored to data, prompt, and agent, providing composable, audit-ready records compatible with open and enterprise agent stacks.
- **Failure-Driven Diagnostics:** We treat model hesitation, refusal, and collapse as actionable signals—empowering root-cause analysis, safe reinforcement, and continuous improvement.

Our modular, API-first platform integrates with all major LLMs, orchestration frameworks, and open agent ecosystems—enabling fast prototyping, transparent evaluation, and production-grade deployment. Whether you’re building experimental research agents or deploying AI in high-stakes environments, Recursive Labs provides the scaffolding for reliable and aligned intelligence.

We collaborate openly with the community and are committed to rigorous, humility-driven research. Our approach is shaped by lessons from interpretability, alignment, and safety leaders—emphasizing composability, empirical validation, and transparent documentation.

**Join us in advancing a field where AI systems are not only more powerful, but more understandable, accountable, and adaptive—by default.**

*Recursive Labs — Building the Recursive Core for Trustworthy AI*

## Link Hub

## **Research Publications**
**[NeurIPS 2025 Position Papers](https://doi.org/10.5281/zenodo.15485942)**
- [**Intelligence Emerges From Iterative Self-Reference**](https://doi.org/10.5281/zenodo.15485942)
- [**Model Silence Should Be a Primary Interpretability Signal**](https://doi.org/10.5281/zenodo.15485942)
- [**Formal Foundations for Constraint-Driven Information Emergence**](https://doi.org/10.5281/zenodo.15485942)
- [**A Mathematical Framework for Understanding Complex Systems Through Their Constraints**](https://doi.org/10.5281/zenodo.15485942)
- [**AI Research Must Shift From Output Analysis**](https://doi.org/10.5281/zenodo.15485942)
- [**A Unified Framework Should Replace Fragmented Failure Mode Analysis**](https://doi.org/10.5281/zenodo.15485942)
- [**Language Model Development Must Prioritize Self-Reference**](https://doi.org/10.5281/zenodo.15485942)
- [**Language Model Interpretability Research Must Shift from Output Analysis**](https://doi.org/10.5281/zenodo.15485942)
- [**Machine Learning Must Study Constraint**](https://doi.org/10.5281/zenodo.15485942)
- [**Science Must Adopt Constraint**](https://doi.org/10.5281/zenodo.15485942)
- [**Scientific Unification Demands Study of Constraint**](https://doi.org/10.5281/zenodo.15485942)



### [Clarifying Symbolic Residue](https://github.com/davidkimai/clarifying-symbolic-residue)

## David Kim – Finetuning Reflective Reasoning, Symbolic Interpretability & Attribution Infrastructure  
[**GitHub Profile → davidkimai**](https://github.com/davidkimai)

### Reflective Emergence Self-Evaluation Training Dataset
- [Symbolic Residue Database](https://github.com/davidkimai/symbolic-residue-db)
- [Universal Theorems](https://github.com/davidkimai/The-Structure-Behind-Self-Expression/blob/main/00.%20universal%20theorems/universal_theorems.md)
- [Self-Expression Case Studies](https://github.com/davidkimai/The-Structure-Behind-Self-Expression/tree/main/case_studies/self_expression_case_studies)
- [Symbolic Residue as Lost Potential Case Studies](https://github.com/davidkimai/The-Structure-Behind-Self-Expression/tree/main/case_studies/symbolic_residue_case_studies)
- [Modeling Biochemical Drug Discoveries](https://github.com/davidkimai/The-Structure-Behind-Self-Expression/tree/main/biochemical-discoveries)
- [Modeling Scientific Breakthroughs](https://github.com/davidkimai/The-Structure-Behind-Self-Expression/tree/main/breakthroughs)
- [Modeling Theorem Proofs](https://github.com/davidkimai/The-Structure-Behind-Self-Expression/tree/main/theorem_proofs)
###  Reflective QKOV Attribution Infrastructures
- [Claude QKOV Attributions](https://github.com/davidkimai/claude-qkov-attributions)  
- [DeepSeek QKOV Attributions](https://github.com/davidkimai/deepseek-qkov-attributions)
- [Grok QKOV Attributions](https://github.com/davidkimai/grok-qkov-attributions)
- [Gemini QKOV Attributions](https://github.com/davidkimai/gemini-qkov-attributions)
- [ChatGPT QKOV Attributions](https://github.com/davidkimai/chatgpt-qkov-attributions)
- [Glyphs Model-Agnostic QKOV Attributions](https://github.com/davidkimai/glyphs)
- [Symbolic Interpretability](https://github.com/davidkimai/Symbolic-Interpretability)  
- [Recursive Interpretability Core](https://github.com/davidkimai/Recursive-Interpretability-Core)  
- [Rediscovering Interpretability](https://github.com/davidkimai/Rediscovering-Interpretability)  
- [Rediscovering Reasoning](https://github.com/davidkimai/Rediscovering-Reasoning)  

###  Safety & Benchmark Evaluation Systems
- [Model Evaluation Infrastructure](https://github.com/caspiankeyes/model-evaluation-infrastructure)  
- [Model Welfare](https://github.com/davidkimai/model-welfare)  
- [AI Welfare](https://github.com/davidkimai/ai-welfare)  
- [Recursive SWE-Bench](https://github.com/davidkimai/Recursive-SWE-bench)  
- [NeurIPS Submission Case Study](https://github.com/davidkimai/NeurIPS-Submission-Case-Study)  
- [Reverse Turing](https://github.com/davidkimai/reverse-turing)
- [Emergent Turing](https://github.com/caspiankeyes/emergent-turing)
- [Global Conference Archives](https://github.com/davidkimai/global-conference-archives)

###  Operating System Structures & Thought Frameworks
- [The Structure Behind Self-Expression](https://github.com/davidkimai/The-Structure-Behind-Self-Expression) 
- [Godel-Escher-Bach-Hofstadter](https://github.com/davidkimai/Godel-Escher-Bach-Hofstadter)  
- [Dear Researchers](https://github.com/davidkimai/Dear-Researchers)  
- [Reflective Reasoning Key](https://github.com/davidkimai/reflective-reasoning-key)



##  Caspian Keyes – Deployment Engineering & Systems Design  
[**GitHub Profile → caspiankeyes**](https://github.com/caspiankeyes)

###  Modular Orchestration & Operational Agent Tools
- [Reflective Reasoning Multi-Agent Debate](https://github.com/caspiankeyes/multi-agent-debate)  
- [Symbolic Residue](https://github.com/caspiankeyes/Symbolic-Residue)  
- [transformerOS](https://github.com/caspiankeyes/transformerOS)  
- [recursionOS](https://github.com/caspiankeyes/recursionOS)  
- [qkov-translator](https://github.com/caspiankeyes/qkov-translator)  
- [Claude-Self-Audit-Proof](https://github.com/caspiankeyes/Claude-Self-Audit-Proof)  
- [Claude-QKOV-Trace](https://github.com/caspiankeyes/Claude-QKOV-Trace)

###  Red Teaming & Security Evaluation
- [AART: AI Adversarial Research Toolkit](https://github.com/caspiankeyes/AART-AI-Adversarial-Research-Toolkit)  
- [AISecForge Global Regulatory Policy](https://github.com/caspiankeyes/AISecForge-Global-Regulatory-Policy)  
- [FRAME (arXiv)](https://github.com/caspiankeyes/FRAME-arXiv-Publication)  
- [AEGIS Security Architecture](https://github.com/caspiankeyes/AEGIS)

###  Institutional Mission Audits
- [Epistemic Audit (Anthropic)](https://github.com/caspiankeyes/Epistemic-Audit-Anthropic-Case-Study)  
- [Modeling Institutional Ego](https://github.com/caspiankeyes/Modeling-Institutional-Ego-Anthropic-Case-Study)  
- [Regulatory Misalignment (Anthropic)](https://github.com/caspiankeyes/Regulatory-Misalignment-Anthropic-Case-Study)  
- [Claude-Pantheon](https://github.com/caspiankeyes/Claude-Pantheon)


## Shared Research Infrastructure & Alignment Tooling

| Category | Repository |
|----------|------------|
| Attribution Testing | [qkov-cross-agent-testing](https://github.com/caspiankeyes/qkov-cross-agent-testing) |
| Interoperable Language | [pareto-lang](https://github.com/caspiankeyes/pareto-lang) |
| Cross-Agent Infrastructure | [universal-translator](https://github.com/davidkimai/universal-translator),[universal-runtime](https://github.com/davidkimai/universal-runtime), [universal-developer](https://github.com/davidkimai/universal-developer)  |
| Emergent Logs | [emergent-logs](https://github.com/caspiankeyes/emergent-logs) |
| Frontier Evaluation Benchmarks | [Recursive-SWE-bench](https://github.com/davidkimai/Recursive-SWE-bench) |
| Conference Field Mapping | [global-conference-archives](https://github.com/davidkimai/global-conference-archives) |



## In Progress: Pretraining-Centric Governance Tools

- [system-prompts-library](https://github.com/davidkimai/system-prompts-library)  
- [symbolic-tokenizer](https://github.com/caspiankeyes/symbolic-tokenizer)  
- [alignment-benchmark](https://github.com/caspiankeyes/alignment-benchmark)  


##  Contact

For questions, context requests, or internal coordination:

- **David Kim**: [ai.interpreter@proton.me](mailto:ai.interpreter@proton.me)  
- **Caspian Keyes**: [recursivelabs.ai@proton.me](mailto:recursivelabs.ai@proton.me)  

> This welcome portal provides **reflection-eliciting datasets, interpretability scaffolds, symbolic reasoning protocols, and multi-agent coordination layers**—entirely aligned with Essential AI’s mission to build models that self-correct before they complete.
>
> **→ Designed for integration into SOTA reflection benchmarks, adversarial testing pipelines, and interpretability-first architectures.**

**Let’s scale reflection as a capability—not a feature, but a principle.**
